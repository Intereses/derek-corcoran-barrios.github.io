---
title: "Clase 5 Modelos"
author: "Derek Corcoran"
date: "`r format(Sys.time(), '%d/%m, %Y')`"
output:
  ioslides_presentation:
    widescreen: true
    incremental: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE, tidy = TRUE, tidy.opts = list(width.cutoff = 50))
library(tidyverse)
library(broom)
library(kableExtra)
library(knitr)
options("kableExtra.html.bsTable" = T)
```

# Modelos

## ¿Qué es un modelo?

* Un modelo es una versión simplificada de la realidad que nos permite hacer inferencias o prediccións sobre una población
* Un modelo es un resumen adecuado de la realidad
* Un modelo es una simplificación or aproximación a la realidad y por ende no reflejará toda la realidad (Burnham y Anderson)
* Todos los modelos estan equivocados, algunos son útiles (George Box)

## Veamos un ejemplo

* ¿Cuánto $CO_2$ captan las plantas?

```{r, echo = FALSE, cache = TRUE}
data("CO2")
knitr::kable(CO2, row.names = FALSE) %>% kable_styling(bootstrap_options = c("striped")) %>% scroll_box(height = "800px", width = "650px")
```

## ¿Será la subespecie?

```{r}
ggplot(CO2, aes(x = Type, y=uptake)) + geom_boxplot(aes(fill = Type), notch = TRUE) + theme_classic()
```

## ¿Será el tratamiento?

```{r}
ggplot(CO2, aes(x = Treatment, y=uptake)) + geom_boxplot(aes(fill = Treatment), notch = TRUE) + theme_classic()
```

## ¿Será la concentración?

```{r}
ggplot(CO2, aes(x = conc, y=uptake)) + geom_point() + theme_classic()
```

# ¿Como lo determinamos?

## Formula de un modelo

```{r, echo = TRUE, eval=FALSE}
alguna_funcion(Y ~ X1 + X2 + ... + Xn, data = data.frame)
```

* **Y:** Variable respuesta (Captación de $CO_2$)
* **`~`:** Explicado por
* **$X_n$:** Variable explicativa n (Subespecie, tratamiento, etc.)
* **data.frame:*** Base de datos (CO2)
* **alguna_funcion:** El modelo a testear (nuestra simplificación de la realidad)

## Algunos modelos en R

```{r Modelos, echo = FALSE}
Modelos <- data.frame(Modelos = c("Prueba de t" ,"ANOVA", "Modelo lineal simple", "modelo lineal generalizado", "Modelo aditivo", "Modelo no lineal", "modelos lineales mixtos", "Boosted regression trees"), Funcion = c("t.test()", "aov()", "lm()", "glm()", "gam()", "nls()", "lmer()", "gbm()"))

kable(Modelos, row.names = FALSE) %>% kable_styling(bootstrap_options = "striped")
```

## ¿Cual usamos para estudiar lo de la planta?

```{r, echo = TRUE}
Fit1 <- lm(uptake ~ Type, data = CO2)
```

* Para este ejercicio usaremos un modelo lineal simple
* Equivalente a un ANOVA

## Usando broom para sacarle mas a tu modelo (glance)

* Para ver datos generales del modelo

```{r, eval = FALSE}
library(broom)
glance(Fit1)
```

```{r, echo=FALSE}
library(broom)
kable(glance(Fit1), digits = 2) %>% kable_styling(bootstrap_options = "striped")
```

## Usando broom para sacarle mas a tu modelo (tidy)

* Para ver parametros del modelo

```{r, eval = FALSE}
tidy(Fit1)
```

```{r, echo=FALSE}
kable(tidy(Fit1)) %>% kable_styling(bootstrap_options = "striped")
```


## Usando broom para sacarle mas a tu modelo (augment)

* Para ver predicciones y residuales del modelo

```{r, eval = FALSE}
augment(Fit1)
```

```{r, echo=FALSE}
knitr::kable(augment(Fit1)) %>% kable_styling(bootstrap_options = c("striped")) %>% scroll_box(height = "300px", width = "900px")
```

## Selección de modelos

* Basado en criterios de información
* Trabajaremos con AIC
* $K$ número de parámetros
* $\ln{(\hat{L})}$ ajuste, mas positivo mejor, mas negativo es malo

$$AIC = 2 K - 2 \ln{(\hat{L})}$$

## Modelos candidatos

```{r, echo = FALSE}
ggplot(CO2, aes(x = conc, y = uptake)) + geom_point(aes(color = Type, shape = Treatment), size = 2)
```


## Modelos candidatos

```{r, echo = TRUE}
Fit1 <- lm(uptake ~ Type, data = CO2)
Fit2 <- lm(uptake ~ Treatment, data = CO2)
Fit3 <- lm(uptake ~ conc, data = CO2)
Fit4 <- lm(uptake ~ Type + Treatment + conc, data = CO2)
Fit5 <- lm(uptake ~ Type + conc + I(log(conc)), data = CO2)
```

# Interpretando modelos

## Modelo 1

* uptake ~ Type

```{r, echo = F}
Pred1 <- CO2
Pred1$Pred <- predict(Fit1, CO2) 
Pred1$SE <- predict(Fit1, CO2, se.fit = T)$se.fit 

ggplot(Pred1, aes(x = conc, y = Pred)) + geom_ribbon(aes(ymax = Pred + SE, ymin = Pred - SE, fill = Type), alpha = 0.5) + geom_path(aes(color = Type, )) + geom_point(aes(x = conc, y = uptake, color = Type)) + theme_bw() 
```

## Modelo 2

* uptake ~ Treatment

```{r, echo = F}
Pred2 <- CO2
Pred2$Pred <- predict(Fit2, CO2) 
Pred2$SE <- predict(Fit2, CO2, se.fit = T)$se.fit 

ggplot(Pred2, aes(x = conc, y = Pred)) + geom_ribbon(aes(ymax = Pred + SE, ymin = Pred - SE, fill = Treatment), alpha = 0.5) + geom_path(aes(color = Treatment)) + geom_point(aes(x = conc, y = uptake, color = Treatment)) + theme_bw() 
```

## Modelo 3

* uptake ~ conc

```{r, echo = F}
Pred3 <- CO2
Pred3$Pred <- predict(Fit3, CO2) 
Pred3$SE <- predict(Fit3, CO2, se.fit = T)$se.fit 

ggplot(Pred3, aes(x = conc, y = Pred)) + geom_ribbon(aes(ymax = Pred + SE, ymin = Pred - SE), alpha = 0.5) + geom_path() + geom_point(aes(x = conc, y = uptake)) + theme_bw() 
```

## Modelo 4

* uptake ~ Type + Treatment + conc

```{r, echo = F}
Pred4 <- CO2
Pred4$Pred <- predict(Fit4, CO2) 
Pred4$SE <- predict(Fit4, CO2, se.fit = T)$se.fit 

ggplot(Pred4, aes(x = conc, y = Pred)) + geom_ribbon(aes(ymax = Pred + SE, ymin = Pred - SE, fill = Type), alpha = 0.5) + geom_path(aes(lty = Type)) + facet_grid(~Treatment) + geom_point(aes(x = conc, y = uptake, color = Type)) + theme_bw() 
```

## Modelo 5

* uptake ~ Type + conc + I(log(conc))

```{r, echo = F}
Pred5 <- CO2
Pred5$Pred <- predict(Fit5, CO2) 
Pred5$SE <- predict(Fit5, CO2, se.fit = T)$se.fit 

ggplot(Pred5, aes(x = conc, y = Pred)) + geom_ribbon(aes(ymax = Pred + SE, ymin = Pred - SE, fill = Type), alpha = 0.5) + geom_line(aes(lty = Type)) + geom_point(aes(x = conc, y = uptake, color = Type)) + theme_bw() 
```

# Seleccion de modelos

## Selección de modelos con broom

```{r, echo = TRUE}
Modelo1 <- glance(Fit1) %>% dplyr::select(r.squared, AIC) %>% mutate(Modelo = "Fit1")
Modelo2 <- glance(Fit2) %>% dplyr::select(r.squared, AIC) %>% mutate(Modelo = "Fit2")
Modelo3 <- glance(Fit3) %>% dplyr::select(r.squared, AIC) %>% mutate(Modelo = "Fit3")
Modelo4 <- glance(Fit4) %>% dplyr::select(r.squared, AIC) %>% mutate(Modelo = "Fit4")
Modelo5 <- glance(Fit5) %>% dplyr::select(r.squared, AIC) %>% mutate(Modelo = "Fit5")

Modelos <- bind_rows(Modelo1, Modelo2, Modelo3, Modelo4, Modelo5) %>% arrange(AIC) %>% mutate(DeltaAIC = AIC-min(AIC))
```

## Selección de modelos con broom

```{r, echo = FALSE}
kable(Modelos)  %>% kable_styling(bootstrap_options = "striped")
```

## No todos los modelos son cubiertos por Broom

```{r, echo = FALSE}
ggplot(CO2, aes(x = conc, y = uptake)) + geom_path(aes(color = Type, lty = Treatment, group = Plant)) + geom_point(aes(color = Type, shape = Treatment), size = 2) 
```


# GLMs

## Distribuciones

```{r}
knitr::include_graphics("Distributions.jpeg", dpi = 300)
```


## Estructura de error

* **family =**
* gaussian (variable dependiente continua)
* binomial (variable dependiente 0 o 1)
* poisson (variable dependiente cuentas 1, 2 ,3 ,4 ,5)
* gamma (variable dependiente continua solo positiva)


## Modelo lineal generalizado (familia: binomial)

```{r, results= "asis"}
library(tidyverse)
train <- read_csv("train.csv") %>% filter(Embarked == "S")
knitr::kable(head(train[,-c(1,4,7,8,9)]), format = "html")
```

## Modelo lineal generalizado (familia: binomial)

```{r}
FitBin <- glm(Survived ~ Fare + Sex, data = train)

DF <- expand.grid(Fare = seq(from = min(train$Fare), to = max(train$Fare), length.out = 50), Prediction = NA, SE = NA, Sex = c("male", "female"))


DF$Prediction <- predict(FitBin, DF, se.fit = TRUE)$fit
DF$SE <- predict(FitBin, DF, se.fit = TRUE)$se.fit

ggplot(DF, aes(x = Fare, y = Prediction)) + geom_ribbon(aes(ymax= Prediction + SE, ymin =Prediction - SE, fill = Sex), alpha = 0.5) + geom_line(aes(lty = Sex)) + theme_classic()

```


## Modelo lineal generalizado (familia: binomial)

```{r}
knitr::kable(broom::tidy(FitBin))
```

```{r}
knitr::kable(broom::glance(FitBin))
```

$R^2$: `r DescTools::PseudoR2(FitBin, "Nagelkerke")`


## Modelo lineal generalizado (familia: binomial)

```{r}
FitBin <- glm(Survived ~ Fare + Sex, data = train)

DF <- expand.grid(Fare = seq(from = -200, to = 1000, length.out = 50), Prediction = NA, SE = NA, Sex = c("male", "female"))


DF$Prediction <- predict(FitBin, DF, se.fit = TRUE)$fit
DF$SE <- predict(FitBin, DF, se.fit = TRUE)$se.fit

ggplot(DF, aes(x = Fare, y = Prediction)) + geom_ribbon(aes(ymax= Prediction + SE, ymin =Prediction - SE, fill = Sex), alpha = 0.5) + geom_line(aes(lty = Sex)) + theme_classic() + geom_hline(yintercept = c(0,1), lty = 2 , color = "red")

```


## Modelo lineal generalizado (familia: binomial)

```{r, results="asis", cache = TRUE}
FitBin2 <- glm(Survived ~ Fare*Sex, data = train, family = binomial())
##1
DF <- expand.grid(Fare = seq(from = min(train$Fare), to = max(train$Fare), length.out = 50), Prediction = NA, SE = NA, Sex = c("male", "female"))

DF$Prediction <- predict(FitBin2, DF, se.fit = TRUE, type = "response")$fit
DF$SE <- predict(FitBin2, DF, se.fit = TRUE,"response")$se.fit


ggplot(DF, aes(x = Fare, y = Prediction)) + geom_ribbon(aes(ymax= Prediction + SE, ymin =Prediction - SE, fill = Sex), alpha = 0.5) + geom_line(aes(lty = Sex)) + theme_classic()
```

## Modelo lineal generalizado (familia: binomial)

```{r}
knitr::kable(broom::tidy(FitBin2))
```

```{r}
knitr::kable(broom::glance(FitBin2))
```

$R^2$: `r DescTools::PseudoR2(FitBin2, "Nagelkerke")`

## Modelo lineal generalizado (familia: binomial)

```{r, results="asis", cache = TRUE}
FitBin2 <- glm(Survived ~ Fare*Sex, data = train, family = binomial())
##1
DF <- expand.grid(Fare = seq(from = -200, to = 1000, length.out = 50), Prediction = NA, SE = NA, Sex = c("male", "female"))

DF$Prediction <- predict(FitBin2, DF, se.fit = TRUE, type = "response")$fit
DF$SE <- predict(FitBin2, DF, se.fit = TRUE,"response")$se.fit


ggplot(DF, aes(x = Fare, y = Prediction)) + geom_ribbon(aes(ymax= Prediction + SE, ymin =Prediction - SE, fill = Sex), alpha = 0.5) + geom_line(aes(lty = Sex)) + theme_classic()
```

## Función link

* Actua sobre $Y$
* family Gaussian, link = identidad
* family Gamma, link = inverso
* family poisson, link  = log
* family binomial, link = logit

$$Logit = log{\frac{p}{1-p}}$$

## Función link

```{r}
x = c(-1, -0.8, 0.1, 0.2, 0.5, 0.8, 1, 2, 2.3)
link = data.frame(Valor = x, Identidad = x, Inverso = 1/x, Log = log(x), logit = log(x/(1-x)))
knitr::kable(link)
```

## Función link

```{r}
x = seq(from = -4, to = 4, by = 0.2)
link = data.frame(Valor = x, Identidad = x, Inverso = 1/x, Log = log(x), logit = log(x/(1-x)))
link2 <- link %>% gather(key = link, value = transformacion, -Valor)
ggplot(link2, aes(x = Valor, y = transformacion)) + geom_line(aes(color = link)) + geom_point(aes(color = link)) + theme_classic() + geom_vline(xintercept = c(0,1), lty = 2 , color = "red")
```


## Expandiendo los modelos que puedo usar paquete caret

* Paquete [caret](http://topepo.github.io/caret/index.html), 238 tipos de modelos distintos 
* Si quieren aprender mucho más acá hay un [tutorial](https://www.youtube.com/watch?v=7Jbb2ItbTC4&t=3s)
* En lo más básico solo una función *train*
* Curso de de machine learning en R?

## función train

* Sirve para cualquier modelo, solo hay que cambiar method
```{r}
library(caret)
Eficiencia <- train(mpg ~ wt, method = "lm", data = mtcars)
glance(Eficiencia$finalModel)
```
***
```{r}
library(caret)
Eficiencia2 <- train(mpg ~ wt, method = "glm", data = mtcars)
glance(Eficiencia2$finalModel)
```

## función train

```{r, cache = TRUE}
library(caret)
Eficiencia3 <- train(mpg ~ wt, method = "bagEarth", data = mtcars)
Eficiencia3$results
```

## función train (clasificación)

```{r, eval = FALSE}
library(caret)
Especies <- train(Species ~. , method = "glm", data = iris)
```

## función train (clasificación)

```{r}
library(caret)
Especies <- train(Species ~. , method = "rpart", data = iris)
Especies$results
```

## función train (clasificación)

```{r}
library(rattle)
library(rpart.plot)
rpart.plot(Especies$finalModel)
```

## Para la próxima clase

* Loops normales y con purrr
* Plantillas de Journals para trabajar desde r (Instalar *rticles*)
* Hay que poder knitear a pdf instalar *tinytex*
